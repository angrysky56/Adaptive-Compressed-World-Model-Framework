{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Knowledge System Demo\n",
    "\n",
    "This notebook demonstrates the basics of the Adaptive Compressed Knowledge Representation System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Add the parent directory to Python path to import the package\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the knowledge system\n",
    "from src.knowledge.adaptive_knowledge_system import AdaptiveKnowledgeSystem, CompressedContextPack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Knowledge System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a knowledge system\n",
    "knowledge_system = AdaptiveKnowledgeSystem()\n",
    "print(\"Knowledge system initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function for async execution in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run async code in notebook\n",
    "async def run_async(coro):\n",
    "    return await coro\n",
    "\n",
    "def execute_async(coro):\n",
    "    return asyncio.run(coro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Knowledge to the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some knowledge about AI concepts\n",
    "async def add_ai_knowledge():\n",
    "    # Add knowledge about machine learning\n",
    "    ml_context_id = await knowledge_system.add_knowledge(\n",
    "        \"Machine Learning is a subset of artificial intelligence that involves training algorithms \"\n",
    "        \"on data to make predictions or decisions without being explicitly programmed to do so. \"\n",
    "        \"Common techniques include neural networks, decision trees, and support vector machines.\",\n",
    "        [\"machine learning\", \"algorithms\", \"neural networks\", \"decision trees\"]\n",
    "    )\n",
    "    \n",
    "    # Add knowledge about neural networks\n",
    "    nn_context_id = await knowledge_system.add_knowledge(\n",
    "        \"Neural Networks are a set of algorithms, modeled loosely after the human brain, that \"\n",
    "        \"are designed to recognize patterns. They interpret sensory data through a kind of machine \"\n",
    "        \"perception, labeling or clustering raw input. They are composed of layers of artificial neurons.\",\n",
    "        [\"neural networks\", \"algorithms\", \"patterns\", \"neurons\"]\n",
    "    )\n",
    "    \n",
    "    # Add knowledge about deep learning\n",
    "    dl_context_id = await knowledge_system.add_knowledge(\n",
    "        \"Deep Learning is a subset of machine learning that uses neural networks with multiple layers \"\n",
    "        \"(deep neural networks) to analyze various factors of data. Deep learning is behind many recent \"\n",
    "        \"advances in AI, including computer vision and natural language processing.\",\n",
    "        [\"deep learning\", \"neural networks\", \"computer vision\", \"natural language processing\"]\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"machine_learning\": ml_context_id,\n",
    "        \"neural_networks\": nn_context_id,\n",
    "        \"deep_learning\": dl_context_id\n",
    "    }\n",
    "\n",
    "context_ids = execute_async(add_ai_knowledge())\n",
    "print(\"Added knowledge with context IDs:\", context_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Knowledge System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for knowledge about neural networks\n",
    "async def query_knowledge(query_text):\n",
    "    results = await knowledge_system.query_knowledge(query_text, max_results=3)\n",
    "    return results\n",
    "\n",
    "query_results = execute_async(query_knowledge(\"How do neural networks work?\"))\n",
    "\n",
    "# Display the results\n",
    "for i, result in enumerate(query_results, 1):\n",
    "    print(f\"Result {i} (Relevance: {result['relevance_score']:.2f})\")\n",
    "    print(f\"Summary: {result['summary']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand a specific context\n",
    "async def expand_context(context_id):\n",
    "    expanded = await knowledge_system.expand_knowledge(context_id)\n",
    "    return expanded\n",
    "\n",
    "nn_expanded = execute_async(expand_context(context_ids[\"neural_networks\"]))\n",
    "\n",
    "print(\"Expanded content:\")\n",
    "print(nn_expanded[\"expanded_content\"])\n",
    "\n",
    "print(\"\\nRelated contexts:\")\n",
    "for related in nn_expanded[\"related_contexts\"]:\n",
    "    print(f\"- {related['summary']} (Relevance: {related['relevance']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update a knowledge context with new information\n",
    "async def update_knowledge(context_id, new_text):\n",
    "    updated = await knowledge_system.update_knowledge(context_id, new_text)\n",
    "    return updated\n",
    "\n",
    "dl_updated = execute_async(update_knowledge(\n",
    "    context_ids[\"deep_learning\"],\n",
    "    \"Deep Learning is a subset of machine learning that uses neural networks with multiple layers \"\n",
    "    \"(deep neural networks) to analyze various factors of data. Recent advances in deep learning \"\n",
    "    \"include transformer models like BERT and GPT, which have revolutionized natural language processing. \"\n",
    "    \"Deep learning is also used in computer vision, reinforcement learning, and generative models.\"\n",
    "))\n",
    "\n",
    "print(f\"Knowledge updated: {dl_updated}\")\n",
    "\n",
    "# Check the updated content\n",
    "if dl_updated:\n",
    "    dl_expanded = execute_async(expand_context(context_ids[\"deep_learning\"]))\n",
    "    print(\"\\nUpdated content:\")\n",
    "    print(dl_expanded[\"expanded_content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simplified visualization of the knowledge graph\n",
    "def visualize_knowledge_graph(knowledge_system):\n",
    "    # Create a graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes for each context\n",
    "    for node in knowledge_system.context_graph.graph.nodes:\n",
    "        G.add_node(node, label=node[:8])\n",
    "    \n",
    "    # Add edges for relationships\n",
    "    for u, v, data in knowledge_system.context_graph.graph.edges(data=True):\n",
    "        G.add_edge(u, v, weight=data.get('weight', 0.5))\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    \n",
    "    # Get edge weights for width\n",
    "    edge_weights = [G[u][v]['weight'] * 5 for u, v in G.edges()]\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=700, node_color='skyblue', alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_weights, alpha=0.5, edge_color='gray')\n",
    "    nx.draw_networkx_labels(G, pos, labels={n: G.nodes[n]['label'] for n in G.nodes()})\n",
    "    \n",
    "    plt.title(\"Knowledge Graph Visualization\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the knowledge graph\n",
    "visualize_knowledge_graph(knowledge_system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Event-Triggered Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the event-triggered update system\n",
    "async def test_event_triggering():\n",
    "    # Create a new context\n",
    "    context_id = await knowledge_system.add_knowledge(\n",
    "        \"Reinforcement Learning is a type of machine learning where an agent learns to make decisions \"\n",
    "        \"by taking actions in an environment to maximize some notion of cumulative reward.\",\n",
    "        [\"reinforcement learning\", \"agent\", \"reward\"]\n",
    "    )\n",
    "    \n",
    "    # Make a small update (shouldn't trigger an update)\n",
    "    small_update = await knowledge_system.update_knowledge(\n",
    "        context_id,\n",
    "        \"Reinforcement Learning is a type of machine learning where an agent learns to make decisions \"\n",
    "        \"by taking actions in an environment to maximize rewards over time.\"\n",
    "    )\n",
    "    \n",
    "    # Make a larger update (should trigger an update)\n",
    "    large_update = await knowledge_system.update_knowledge(\n",
    "        context_id,\n",
    "        \"Reinforcement Learning is an area of machine learning concerned with how intelligent agents \"\n",
    "        \"ought to take actions in an environment in order to maximize the notion of cumulative reward. \"\n",
    "        \"Key algorithms include Q-learning, SARSA, and Deep Q Networks (DQN). RL has been applied to \"\n",
    "        \"robotics, game playing, and autonomous vehicles.\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"context_id\": context_id,\n",
    "        \"small_update_triggered\": small_update,\n",
    "        \"large_update_triggered\": large_update\n",
    "    }\n",
    "\n",
    "event_results = execute_async(test_event_triggering())\n",
    "\n",
    "print(f\"Event-Triggered Update Test Results:\")\n",
    "print(f\"Context ID: {event_results['context_id']}\")\n",
    "print(f\"Small update triggered: {event_results['small_update_triggered']}\")\n",
    "print(f\"Large update triggered: {event_results['large_update_triggered']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Threshold Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract threshold history\n",
    "def analyze_thresholds(knowledge_system):\n",
    "    event_trigger = knowledge_system.event_trigger\n",
    "    history = event_trigger.event_history\n",
    "    \n",
    "    if not history:\n",
    "        print(\"No event history available\")\n",
    "        return\n",
    "    \n",
    "    # Group by context ID\n",
    "    contexts = {}\n",
    "    for event in history:\n",
    "        context_id = event['context_id']\n",
    "        if context_id not in contexts:\n",
    "            contexts[context_id] = []\n",
    "        contexts[context_id].append(event)\n",
    "    \n",
    "    # Plot threshold adaptation for the context with the most events\n",
    "    most_active_context = max(contexts.items(), key=lambda x: len(x[1]))\n",
    "    context_id, events = most_active_context\n",
    "    \n",
    "    print(f\"Analyzing threshold adaptation for context {context_id}\")\n",
    "    print(f\"Total events: {len(events)}\")\n",
    "    \n",
    "    # Extract data for plotting\n",
    "    timestamps = [e['timestamp'] for e in events]\n",
    "    magnitudes = [e['change_magnitude'] for e in events]\n",
    "    triggered = [e['was_triggered'] for e in events]\n",
    "    \n",
    "    # Convert timestamps to relative time\n",
    "    start_time = min(timestamps)\n",
    "    relative_times = [(t - start_time) for t in timestamps]\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot change magnitudes\n",
    "    plt.scatter(relative_times, magnitudes, c=['green' if t else 'red' for t in triggered], \n",
    "                alpha=0.7, s=100, label='Change Magnitude')\n",
    "    \n",
    "    # Add legend and labels\n",
    "    plt.axhline(y=event_trigger.get_threshold(context_id), color='blue', linestyle='--', \n",
    "                label=f'Current Threshold: {event_trigger.get_threshold(context_id):.3f}')\n",
    "    plt.xlabel('Relative Time (seconds)')\n",
    "    plt.ylabel('Change Magnitude')\n",
    "    plt.title('Event Triggering Analysis')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_thresholds(knowledge_system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the core functionality of the Adaptive Compressed Knowledge Representation System:\n",
    "\n",
    "1. Adding knowledge to the system\n",
    "2. Querying for relevant information\n",
    "3. Expanding context to get detailed information\n",
    "4. Updating knowledge with new information\n",
    "5. Visualizing the knowledge graph\n",
    "6. Testing the event-triggered update system\n",
    "7. Analyzing threshold adaptation\n",
    "\n",
    "These capabilities form the foundation of the Adaptive Compressed World Model Framework, allowing for efficient management of knowledge in memory and storage while maintaining the ability to retrieve detailed information when needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
